{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using LSTM to write Shakepeare.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4crRppJUF44",
        "outputId": "e9c9c07e-43b2-4c31-88c8-7de13def7542"
      },
      "source": [
        "!wget --no-check-certificate \\\r\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\r\n",
        "    -O /tmp/sonnets.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-30 12:42:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.142.128, 74.125.28.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-01-30 12:42:59 (99.2 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb9ltsmCUL1X"
      },
      "source": [
        "f=open(\"/tmp/sonnets.txt\",\"r\")\r\n",
        "f=f.read()\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6NoGkOLUcgE"
      },
      "source": [
        "corpus=f.lower().split(\"\\n\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS0-C7rXWIfG"
      },
      "source": [
        "import tensorflow.keras as keras\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZCH1xQPWY9u"
      },
      "source": [
        "token=Tokenizer(oov_token=\"!@#$REDCZ323\")\r\n",
        "token.fit_on_texts(corpus)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovTYuhi2a6ti",
        "outputId": "0bd4f70c-03a6-4827-a03d-1034104a2c08"
      },
      "source": [
        "nodes=len(token.index_word)\r\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS5pUSVLWon1"
      },
      "source": [
        "tokenized_sentences=[]\r\n",
        "for i in (corpus):\r\n",
        "  converted=token.texts_to_sequences([i])[0]\r\n",
        "  for j in range(1,len(converted)):\r\n",
        "    tokenized_sentences.append(converted[:j+1])\r\n",
        "  "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6bd4uyFYOcl"
      },
      "source": [
        "max_len=max([len(j) for j in tokenized_sentences])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4S7OYx3Y3c_"
      },
      "source": [
        "padded_sentences=pad_sequences(tokenized_sentences,maxlen=max_len)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6tdGHO4YJ5U"
      },
      "source": [
        "data,label=padded_sentences[:,:-1],padded_sentences[:,-1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NNgGda-ZWtl"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM,Bidirectional,GRU,Dense,Embedding"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBV-D5U5awRP"
      },
      "source": [
        "model=Sequential()\r\n",
        "model.add(Embedding(nodes+1,32,input_length=max_len-1))\r\n",
        "model.add(Bidirectional(GRU(32)))\r\n",
        "model.add(Dense(128,activation=\"relu\"))\r\n",
        "model.add(Dense(nodes+1,activation=\"softmax\"))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESoloqJcbIA4"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzdk1HUzclCv"
      },
      "source": [
        "model.fit(data,label,epochs=500,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69V94CHOjweX",
        "outputId": "3f44e2e2-fd02-4f8d-e883-545118d5be45"
      },
      "source": [
        "sent=\"fleece made another gay\"\r\n",
        "\r\n",
        "token_sent=token.texts_to_sequences([sent])\r\n",
        "padded=pad_sequences(token_sent,maxlen=10)\r\n",
        "padded\r\n",
        "model.predict_classes(padded)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kUFJ2KxmgRx",
        "outputId": "48165c80-87b2-4bc2-b76a-0128016257f4"
      },
      "source": [
        "target_words=100\r\n",
        "\r\n",
        "for j in range(target_words):\r\n",
        "  token_sent=token.texts_to_sequences([sent])\r\n",
        "  padded=pad_sequences(token_sent,maxlen=10)\r\n",
        "  value=model.predict_classes(padded)\r\n",
        "  for i,j in token.index_word.items():\r\n",
        "    if i==value:\r\n",
        "      word=j\r\n",
        "      break\r\n",
        "  sent=sent+\" \"+ word\r\n",
        "\r\n",
        "print(sent)\r\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fleece made another gay all ornament thee doth owest live doth now be thy granting ' knife true thy might be take the time for praise to you so near slain thy 'will ' knife brought to make me be your to thou leisure be it thy 'will ' doth might see behind thee look to be convert night doth part away now dead doth love bearing held heart doth lie it love thee the fair ' show thee be i now you do it not fairer made so speed can see back to me in this more well is not doth thee it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_s0i1YEqtg9"
      },
      "source": [
        "import io\r\n",
        "\r\n",
        "words=io.open(\"shakespear.txt\",mode=\"w\",encoding=\"utf-8\")\r\n",
        "words.write(sent)\r\n",
        "\r\n",
        "words.close()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEj-vyC7p8XM",
        "outputId": "65785a0c-5fe3-487c-d0d4-c7e555802ffb"
      },
      "source": [
        "f=open(\"shakespear.txt\")\r\n",
        "for i in f:\r\n",
        "  i=i.split(\",\")\r\n",
        "  print(i)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"fleece made another gay all ornament thee doth owest live doth now be thy granting ' knife true thy might be take the time for praise to you so near slain thy 'will ' knife brought to make me be your to thou leisure be it thy 'will ' doth might see behind thee look to be convert night doth part away now dead doth love bearing held heart doth lie it love thee the fair ' show thee be i now you do it not fairer made so speed can see back to me in this more well is not doth thee it\"]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}